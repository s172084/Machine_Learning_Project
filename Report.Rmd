---
title: "Diamonds analysis"
author:
  - "Oriade Simpson (s172084)"
  - "Pietro Lombardo (s231756)"
date: '2023-09-05'
output:
  pdf_document:
    keep_tex: true
    includes:
      in_header: columns.tex
  html_document:
    df_print: paged
    css: columns.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(MASS)
library(ggplot2)
library(data.table)
library(mltools)
library(reshape)
library(reshape2)
library(rmarkdown)
library(tidyverse)
library(knitr)

data(diamonds)
# ctrl + alt + I
```


Contribution Table 
===
------------------------------------------------------------

Task          |     Oriade    |     Pietro    |
--------------|:-------------:|:-------------:|
**Student ID**|   s172084     |    s231756    |
------------- |-------------- | ------------- | 
Question 1    |       x       |               |   
------------- | ------------- | ------------- |
Question 2    |       x       |               | 
------------- | ------------- | ------------- |
Question 3    |               |       x       |  
------------- | ------------- | ------------- |
Question 4    |               |       x       |
------------- | ------------- | ------------- |
Exam Prob 1   |               |       x       | 
------------- | ------------- | ------------- |
Exam Prob 2   |       x       |               |
------------- | ------------- | ------------- |
Exam Prob 3   |       x       |               |
------------- | ------------- | ------------- |
Exam Prob 4   |               |       x       |
------------- | ------------- | ------------- |
Exam Prob 5   |               |       x       |
------------- | ------------- | ------------- |
Exam Prob 6   |       x       |               |

# 1) Description of the dataset

- Explain what your data is about. I.e. what is the overall problem of
interest?
- Provide a reference to where you obtained the data.
- Summarize previous analysis of the data. (i.e. go through one or two
of the original source papers and read what they did to the data and
summarize their results).
- You will be asked to apply (1) classification and (2) regression on your
data in the next report. For now, we want you to consider how this should
be done. Therefore:
Explain, in the context of your problem of interest, what you hope to
accomplish/learn from the data using these techniques?.
Explain which attribute you wish to predict in the regression based on
which other attributes? Which class label will you predict based on which
other attributes in the classification task?
If you need to transform the data in order to carry out these tasks, explain
roughly how you plan to do this.

One of these tasks (1)â€“(5) is likely more relevant than the rest and will be
denoted the main machine learning aim in the following. The purpose of the 
following questions, which asks you to describe/visualize the data, is to
allow you to reflect on the feasibility of this task.

# 2) Explanation of the attributes of the data

- Describe if the attributes are discrete/continuous, Nominal/Ordinal/Interval/
Ratio,
- Give an account of whether there are data issues (i.e. missing values or
corrupted data) and describe them if so.
- Include basic summary statistics of the attributes.

If your data set contains many similar attributes, you may restrict yourself to
describing a few representative features (apply common sense).

# 3) Data visualization

## Principal component analysis

The aim of the Principal Component Analysis ("PCA" from now on), is to simplify
the problem dimension by reducing the number of variables which explains the
behavior of the diamonds' price.

The PCA requires the standardization of the attributes so that the variability of
each of them is comparable. But such operation cannot be carried out for 
non-numeric values, like the three ordinal variables *cut*, *color*
and *clarity*. For these reason they are converted into ordinal numbers 
(from 1 to the upper level number) according to their ranking.

After these operations, the dataset appears as below:

```{r}
Dia <- as.data.frame(diamonds)
Dia$cut <- as.numeric(Dia$cut)
Dia$color <- as.numeric(Dia$color)
Dia$clarity <- as.numeric(Dia$clarity)

N <- dim(Dia)[1] # number of rows of the new one-hot-encoded dataframe
M <- dim(Dia)[2] # number of columns of the new one-hot-encoded dataframe

kable(head(Dia), caption = "Head of the diamonds dataset arranged for the PCA")
```

Now the dataset contains all numeric variables, so the next step is to compare
the standard deviations of each variable and check whether they are different.

Below the standard deviations of the variables are shown:

```{r}
stds <- apply(Dia, 2, sd)
print(round(stds,digits=2))
```

Since standard deviation of *price* is some orders of magnitude larger than the 
others, the dataset has to be standardized by subtracting the mean and dividing
by the standard deviation of the whole set of observations of that variable.
```{r}
D_pca <- t(apply(Dia, 1, "-", colMeans(Dia)))
D_pca <- t(apply(D_pca, 1, "*", 1 / stds))
D_pca <- as.data.frame(D_pca)
```

:::::: {.cols data-latex=""}

::: {.col data-latex="{0.55\textwidth}"}
```{r, echo=FALSE, fig.width=5, fig.height=4}
S <- svd(D_pca)
diagS <- S$d
rho <- diagS^2 / sum(diagS^2)

threshold <- 0.9

xlimits <- c(1, M)
plot(rho,
     type = "o",
     main = "Variance explained by principal componenets",
     xlab = "Principal components",
     ylab = "Variance explained",
     xlim = xlimits,
     ylim = c(0, 1),
     col = "blue"
)

lines(cumsum(rho), type = "o", col = "orange")
lines(xlimits, c(threshold, threshold), lty = "dashed")

legend("right", # Define position
       legend = c("Cumulative", "Individual", "Threshold"), # Set strings for legend
       col = c("orange", "blue", "black"), lty = c(1, 1, 2), # Match appereance of lines
       cex = 1, bg = "lightblue"
) # Setup how the box looks (cex controls size)
```
:::

::: {.col data-latex="{0.05\textwidth}"}
\ 
<!-- an empty Div (with a white space), serving as
a column separator -->
:::

::: {.col data-latex="{0.4\textwidth}"}

The new standardized dataset can be now used to perform the Singular Value
Decomposition (SVD). By the extraction of the diagonal of the matrix $\Sigma$,
it can be seen how much variance is explained by each principal component.
The cumulative explained variance should reach the percentage of 90% in order
to describe properly the main features of the dataset. 

The figure below shows that the first 4 principal components explain little less 
than the 90% of variance:
:::
::::::



# 4) Results: what data have shown
